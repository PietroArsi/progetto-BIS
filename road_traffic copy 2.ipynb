{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Traffic Fine Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_raw = pm4py.read_xes(\"Road_Traffic_Fine_Management_Process.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_raw = pm4py.format_dataframe(log_raw, case_id='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "log_raw['time:timestamp'] = pd.to_datetime(log_raw['time:timestamp'])\n",
    "\n",
    "log_raw.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw log analysis\n",
    "\n",
    "num_events = len(log_raw)\n",
    "num_cases = len(log_raw['case:concept:name'].unique())\n",
    "print(f\"Number of events: {num_events}\\nNumber of cases: {num_cases}\")\n",
    "\n",
    "start_activities = pm4py.get_start_activities(log_raw)\n",
    "end_activities = pm4py.get_end_activities(log_raw)\n",
    "all_activities = log_raw[\"concept:name\"].unique().tolist()\n",
    "print(f\"Start activities: {start_activities}\\nEnd activities: {end_activities}\\nAll activites: {all_activities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which columns have NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = log_raw.copy()\n",
    "\n",
    "for col in log_df:\n",
    "    if log_df[col].isna().any():\n",
    "        print(f\"{col.ljust(22, ' ')}: missing values\")\n",
    "    else:\n",
    "        print(f\"{col.ljust(22, ' ')}: clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change NaN values to _zero_ in columns _amount_, _paymentAmount_, _totalPaymentAmount_ and _expense_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df[\"amount\"] = log_df[\"amount\"].fillna(0)\n",
    "log_df[\"paymentAmount\"] = log_df[\"paymentAmount\"].fillna(0)\n",
    "log_df[\"totalPaymentAmount\"] = log_df[\"totalPaymentAmount\"].fillna(0)\n",
    "log_df[\"expense\"] = log_df[\"expense\"].fillna(0)\n",
    "\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove matricola column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove attribute matricola because it's always either NaN or 0, so it's not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_df[\"matricola\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.drop([\"matricola\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns' names to improve readability of the datalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_df.rename(columns={\"amount\" : \"amount\",\n",
    "#                         \"expense\" : \"extraAmount\",\n",
    "#                         \"paymentAmount\": \"paymentAmount\",\n",
    "#                         \"totalPaymentAmount\" : \"totalAmount\"}, inplace=True)\n",
    "\n",
    "# log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix _amount_ column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collapse _amount_, _expense_ and _paymentAmount_ in the _amount_ column to make the datalog more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctAmount(log_row):\n",
    "    activity = log_row[\"concept:name\"]\n",
    "\n",
    "    if activity == \"Create Fine\" or activity == \"Add Penalty\":\n",
    "        return log_row[\"amount\"]\n",
    "    elif activity == \"Send Fine\":\n",
    "        return log_row[\"expense\"]\n",
    "    elif activity == \"Payment\":\n",
    "        return log_row[\"paymentAmount\"]\n",
    "    return 0\n",
    "\n",
    "log_df[\"amount\"] = log_df.apply(correctAmount, axis=\"columns\")\n",
    "\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add _dueAmount_ column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track more easily of how much money is needed in a case, a _dueAmount_ column where the incremental sum of _amount_ is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr_amount = 0\n",
    "last_case = None\n",
    "def incrementalDueAmount(log_row):\n",
    "    global incr_amount, last_case\n",
    "    if last_case == None or log_row[\"case:concept:name\"] != last_case:\n",
    "        last_case = log_row[\"case:concept:name\"]\n",
    "        incr_amount = log_row[\"amount\"]\n",
    "    else:\n",
    "        incr_amount += log_row[\"amount\"]\n",
    "    return incr_amount\n",
    "\n",
    "log_df[\"dueAmount\"] = log_df.apply(incrementalDueAmount, axis=\"columns\")\n",
    "\n",
    "log_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add _status_ and _completed_ columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column _status_ with a more readable description of the _dismissal_ column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setStatus(log_row):\n",
    "    dismissal = log_row[\"dismissal\"]\n",
    "\n",
    "    if dismissal == \"#\":\n",
    "        return \"Prefecture\"\n",
    "    elif dismissal == \"G\":\n",
    "        return \"Judge\"\n",
    "    elif dismissal == \"NIL\":\n",
    "        return \"Not Payed\"\n",
    "    elif pd.isna(dismissal):\n",
    "        return \"Unknown\"\n",
    "    return dismissal\n",
    "\n",
    "log_df[\"status\"] = log_df.apply(setStatus, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column _completed_, based on _status_ column, that shows if a process is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCompleted(log_row):\n",
    "    status = log_row[\"status\"]\n",
    "\n",
    "    if status in [\"Prefecture\", \"Judge\"]:\n",
    "        return \"Yes\"\n",
    "    elif status in [\"Not Payed\", \"Unknown\"]:\n",
    "        return \"No\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "log_df[\"completed\"] = log_df.apply(setCompleted, axis=\"columns\")\n",
    "\n",
    "log_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change column order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change order of columns to make the dataframe more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp', # general attributes\n",
    "            'amount', 'expense', 'points', 'paymentAmount', # number attributes\n",
    "            'totalPaymentAmount', 'dueAmount', # current total amount paid by offender and total due (sum of fines, expenses and penalties)\n",
    "            'dismissal', 'status', \"completed\", # status code\n",
    "            'lastSent', 'vehicleClass', 'article', 'notificationType',\n",
    "            'lifecycle:transition', '@@index', '@@case_index']\n",
    "\n",
    "log_df = log_df[columns]\n",
    "\n",
    "log_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log = log_df.copy(deep=True)\n",
    "\n",
    "num_events = len(log_raw)\n",
    "num_cases = len(log_raw['case:concept:name'].unique())\n",
    "print(f\"Number of events: {num_events}\\nNumber of cases: {num_cases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown-coded cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cases with \"unknown\" as _completed_ code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log = filtered_log[filtered_log['completed'] != \"Unknown\"]\n",
    "\n",
    "# unknown_cases = pm4py.filter_trace_attribute_values(filtered_log, 'completed', [\"Unknown\"], retain=True)\n",
    "# filtered_log = filtered_log[filtered_log[\"completed\"] != \"Unknown\"]\n",
    "# filtered_log = pd.concat([filtered_log, unknown_cases]).drop_duplicates(keep=False)\n",
    "\n",
    "legal_events = len(filtered_log)\n",
    "all_events = len(log_df)\n",
    "# print(f\"Filtered cases: {len(filtered_log['case:concept:name'].unique())}\")\n",
    "print(f\"Filtered events: {legal_events}/{all_events} ({round((legal_events/all_events) * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero duration cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate some statistics about raw logs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_durations = pm4py.get_all_case_durations(log_df)\n",
    "min_raw = min(case_durations)\n",
    "max_raw = max(case_durations)\n",
    "mean_raw = np.mean(case_durations)\n",
    "\n",
    "print(f\"Min Case Duration: {min_raw}\\nMax Case Duration: {max_raw}\\nMean Case Duration: {mean_raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter cases with duration 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_not_zero = min([x for x in case_durations if x>0])\n",
    "print(min_not_zero)\n",
    "print(max_raw)\n",
    "filtered_log = pm4py.filter_case_performance(filtered_log, min_not_zero, max_raw)\n",
    "\n",
    "legal_cases = len(filtered_log['case:concept:name'].unique())\n",
    "all_cases = len(log_df['case:concept:name'].unique())\n",
    "print(f\"Filtered cases: {legal_cases}/{all_cases} ({round((legal_cases/all_cases) * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start/End activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cases with illegal start activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pm4py.get_start_activities(filtered_log))\n",
    "\n",
    "# filtered_log = pm4py.filter_start_activities(filtered_log, ['Create Fine'])\n",
    "\n",
    "# legal_start_cases = len(filtered_log['case:concept:name'].unique())\n",
    "# all_cases = len(log_df['case:concept:name'].unique())\n",
    "# print(f\"Filtered events: {len(filtered_log)}\")\n",
    "# print(f\"Filtered cases: {legal_start_cases}/{all_cases} ({round((legal_start_cases/all_cases) * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cases with illegal end activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm4py.get_end_activities(filtered_log))\n",
    "\n",
    "filtered_log = pm4py.filter_end_activities(filtered_log, ['Payment', 'Send for Credit Collection', 'Send Appeal to Prefecture', 'Appeal to Judge'])\n",
    "\n",
    "legal_cases = len(filtered_log['case:concept:name'].unique())\n",
    "all_cases = len(log_df['case:concept:name'].unique())\n",
    "print(f\"Filtered events: {len(filtered_log)}\")\n",
    "print(f\"Filtered cases: {legal_cases}/{all_cases} ({round((legal_cases/all_cases) * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Uplift Trail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starting point of the project is the log, provided as an ```.xes``` file. The log is processed in two phases: cleaning and filtering. In the cleaning process, the log is converted to a DataFrame, compatible with the libraries used, some parts of the log are removed (_matricola_), changed (_amount_) or added (_status_, _completed_, etc.). In the filtering process, data not useful for analysis are removed through a series of filters (time, values and activies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these two preliminary phases, statistical methods are used to do a general analysis of the data contained in the log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General case durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_durations = pm4py.get_all_case_durations(filtered_log)\n",
    "min_duration = min(case_durations)\n",
    "min_time = datetime.timedelta(seconds=min_duration)\n",
    "max_duration = max(case_durations)\n",
    "max_time = datetime.timedelta(seconds=max_duration)\n",
    "mean_duration = np.mean(case_durations)\n",
    "mean_time = datetime.timedelta(seconds=mean_duration)\n",
    "\n",
    "print(f\"Min Case Duration: {min_duration} -> {min_time}\")\n",
    "print(f\"Max Case Duration: {max_duration} -> {max_time}\")\n",
    "print(f\"Mean Case Duration: {mean_duration} -> {mean_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_durations_df = filtered_log.groupby('case:concept:name', as_index=False).agg(\\\n",
    "    StartTime = ('time:timestamp', lambda x: x.min()),\n",
    "    Duration = ('time:timestamp', lambda x: x.max() - x.min())\n",
    ")\n",
    "\n",
    "def format_duration(row):\n",
    "    total_seconds = int(row.total_seconds())\n",
    "    # hours, remainder = divmod(total_seconds, 3600)\n",
    "    # minutes, seconds = divmod(remainder, 60)\n",
    "    # return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "    return total_seconds\n",
    "\n",
    "case_durations_df['Duration'] = case_durations_df['Duration'].apply(format_duration)\n",
    "\n",
    "def pick_year(row):\n",
    "    return datetime.datetime.strptime(str(row[\"StartTime\"]), \"%Y-%m-%d %H:%M:%S%z\").year\n",
    "\n",
    "def pick_month(row):\n",
    "    return datetime.datetime.strptime(str(row[\"StartTime\"]), \"%Y-%m-%d %H:%M:%S%z\").month\n",
    "\n",
    "def pick_day(row):\n",
    "    return datetime.datetime.strptime(str(row[\"StartTime\"]), \"%Y-%m-%d %H:%M:%S%z\").day\n",
    "\n",
    "case_durations_df[\"StartYear\"] = case_durations_df.apply(pick_year, axis=\"columns\")\n",
    "case_durations_df[\"StartMonth\"] = case_durations_df.apply(pick_month, axis=\"columns\")\n",
    "case_durations_df[\"StartDay\"] = case_durations_df.apply(pick_day, axis=\"columns\")\n",
    "\n",
    "case_durations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [int(x) for x in case_durations_df[\"StartYear\"].unique().tolist()]\n",
    "years.sort()\n",
    "\n",
    "means = []\n",
    "for x in years:\n",
    "    filtered_durations = case_durations_df[case_durations_df[\"StartYear\"] == x]\n",
    "    means.append(filtered_durations[\"Duration\"].mean())\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(years, means)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Mean Duration (seconds)\")\n",
    "plt.title(\"Case duration by year\")\n",
    "# plt.yticks(means, means)\n",
    "plt.xticks(years, years, rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case durations by month of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [int(x) for x in case_durations_df[\"StartMonth\"].unique().tolist()]\n",
    "months.sort()\n",
    "\n",
    "means = []\n",
    "for x in months:\n",
    "    filtered_durations = case_durations_df[case_durations_df[\"StartMonth\"] == x]\n",
    "    means.append(filtered_durations[\"Duration\"].mean())\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(months, means)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Mean Duration (seconds)\")\n",
    "plt.title(\"Case duration by month\")\n",
    "# plt.yticks(means, means)\n",
    "plt.xticks(months, [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case frequency by duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = [\"Less than 1 day\",\n",
    "            \"Less than 1 week\",\n",
    "            \"Less than 1 month\",\n",
    "            \"Less than 6 months\",\n",
    "            \"Less than 1 year\",\n",
    "            \"Less than 2 years\",\n",
    "            \"Less than 5 years\",\n",
    "            \"Others\"]\n",
    "freqs = [len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24]), # 1 day\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24 * 7]), # 1 week\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24*7 * 4]), # 1 month\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24*7*4 * 6]), # 6 months\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24 * 365]), # 1 year\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24*365 * 2]), # 2 years\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24*365 * 5]), # 5 years\n",
    "            len(case_durations_df)]\n",
    "\n",
    "for x in range(len(freqs)-1, 0, -1):\n",
    "    freqs[x] -= freqs[x-1]\n",
    "\n",
    "for x in range(len(freqs)):\n",
    "    print(f\"{xlabels[x].ljust(20, ' ')}: {str(freqs[x]).ljust(5, ' ')} ({round(freqs[x]/len(case_durations_df) * 100, 2)}%)\")\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(xlabels, freqs)\n",
    "plt.xlabel(\"Duration\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Case frequency by duration\")\n",
    "\n",
    "y_custom_ticks = [x*5000 for x in range(10)]\n",
    "y_custom_ticks.remove(5000)\n",
    "y_custom_ticks.append(min(freqs[:len(freqs)-1]))\n",
    "y_custom_ticks.append(max(freqs))\n",
    "y_custom_ticks.sort()\n",
    "\n",
    "plt.yticks(y_custom_ticks)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisogna fare altre analisi statistiche ma dipendono da cosa si vuole dimostrare, da continuare più avanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cerco di capire perché alcuni casi durano tanto\n",
    "# tanto = più di 1 anno\n",
    "\n",
    "# case_ids = case_durations_df.unique().tolist()\n",
    "\n",
    "log_steps = filtered_log.copy(deep=True)\n",
    "\n",
    "durations_short = case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24 * 365]\n",
    "durations_long = case_durations_df[case_durations_df[\"Duration\"] > 60*60*24 * 365]\n",
    "\n",
    "# last_timestamp = 0\n",
    "# def time_from_previous_activity(row):\n",
    "#     global last_timestamp\n",
    "#     if row[\"concept:name\"] == \"Create Fine\":\n",
    "#         last_timestamp = row[\"time:timestamp\"]\n",
    "#         return 0\n",
    "#     else:\n",
    "#         elapsed_time = row[\"time:timestamp\"] - last_timestamp\n",
    "#         last_timestamp = row[\"time:timestamp\"]\n",
    "#         return elapsed_time.total_seconds()\n",
    "\n",
    "# log_steps[\"step_duration\"] = log_steps.apply(time_from_previous_activity, axis=\"columns\")\n",
    "\n",
    "# log_steps.head(10)\n",
    "\n",
    "# log_steps[log_steps[\"amount\"] == log_steps[\"amount\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_variants_info(input_log, k=5):\n",
    "    filtered_log_top = pm4py.filter_variants_top_k(input_log, k)\n",
    "\n",
    "    num_events = len(filtered_log)\n",
    "    num_events_top = len(filtered_log_top)\n",
    "    num_cases = len(filtered_log['case:concept:name'].unique())\n",
    "    num_cases_top = len(filtered_log_top['case:concept:name'].unique())\n",
    "    print(f\"Number of events: {num_events_top}/{num_events} ({round(num_events_top/num_events * 100, 2)}%)\")\n",
    "    print(f\"Number of cases: {num_cases_top}/{num_cases} ({round(num_cases_top/num_cases * 100, 2)}%)\")\n",
    "\n",
    "    net, im, fm = pm4py.discover_petri_net_inductive(filtered_log_top)\n",
    "    pm4py.view_petri_net(net, im, fm, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_variants_info(filtered_log, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_variants_info(filtered_log, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_variants_info(filtered_log, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_variants_info(filtered_log, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conformance Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizational Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aaa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
