{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Traffic Fine Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_raw = pm4py.read_xes(\"Road_Traffic_Fine_Management_Process.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_raw = pm4py.format_dataframe(log_raw, case_id='case:concept:name', activity_key='concept:name', timestamp_key='time:timestamp')\n",
    "log_raw['time:timestamp'] = pd.to_datetime(log_raw['time:timestamp'])\n",
    "\n",
    "log_raw.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw log analysis\n",
    "\n",
    "num_events = len(log_raw)\n",
    "num_cases = len(log_raw['case:concept:name'].unique())\n",
    "print(f\"Number of events: {num_events}\\nNumber of cases: {num_cases}\")\n",
    "\n",
    "start_activities = pm4py.get_start_activities(log_raw)\n",
    "end_activities = pm4py.get_end_activities(log_raw)\n",
    "all_activities = log_raw[\"concept:name\"].unique().tolist()\n",
    "print(f\"Start activities: {start_activities}\\nEnd activities: {end_activities}\\nAll activites: {all_activities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which columns have NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = log_raw.copy()\n",
    "\n",
    "for col in log_df:\n",
    "    if log_df[col].isna().any():\n",
    "        print(f\"{col.ljust(22, ' ')}: missing values\")\n",
    "    else:\n",
    "        print(f\"{col.ljust(22, ' ')}: clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change NaN values to _zero_ in columns _amount_, _paymentAmount_, _totalPaymentAmount_ and _expense_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df[\"amount\"] = log_df[\"amount\"].fillna(0)\n",
    "log_df[\"paymentAmount\"] = log_df[\"paymentAmount\"].fillna(0)\n",
    "log_df[\"totalPaymentAmount\"] = log_df[\"totalPaymentAmount\"].fillna(0)\n",
    "log_df[\"expense\"] = log_df[\"expense\"].fillna(0)\n",
    "\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove matricola column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove attribute matricola because it's always either NaN or 0, so it's not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_df[\"matricola\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.drop([\"matricola\"], axis=\"columns\", inplace=True)\n",
    "\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns' names to improve readability of the datalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_df.rename(columns={\"amount\" : \"amount\",\n",
    "#                         \"expense\" : \"extraAmount\",\n",
    "#                         \"paymentAmount\": \"paymentAmount\",\n",
    "#                         \"totalPaymentAmount\" : \"totalAmount\"}, inplace=True)\n",
    "\n",
    "# log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix _amount_ column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collapse _amount_, _expense_ and _paymentAmount_ in the _amount_ column to make the datalog more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctAmount(log_row):\n",
    "    activity = log_row[\"concept:name\"]\n",
    "\n",
    "    if activity == \"Create Fine\" or activity == \"Add Penalty\":\n",
    "        return log_row[\"amount\"]\n",
    "    elif activity == \"Send Fine\":\n",
    "        return log_row[\"expense\"]\n",
    "    elif activity == \"Payment\":\n",
    "        return log_row[\"paymentAmount\"]\n",
    "    return 0\n",
    "\n",
    "log_df[\"amount\"] = log_df.apply(correctAmount, axis=\"columns\")\n",
    "\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add _dueAmount_ column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track more easily of how much money is needed in a case, a _dueAmount_ column where the incremental sum of _amount_ is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incr_amount = 0\n",
    "# last_case = None\n",
    "# def incrementalDueAmount(log_row):\n",
    "#     global incr_amount, last_case\n",
    "#     if last_case == None or log_row[\"case:concept:name\"] != last_case:\n",
    "#         last_case = log_row[\"case:concept:name\"]\n",
    "#         incr_amount = log_row[\"amount\"]\n",
    "#     elif log_row[\"concept:name\"] != \"Payment\":\n",
    "#         incr_amount += log_row[\"amount\"]\n",
    "#     return incr_amount\n",
    "\n",
    "# log_df[\"dueAmount\"] = log_df.apply(incrementalDueAmount, axis=\"columns\")\n",
    "\n",
    "# log_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add _elapsed_ column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_timestamp = None\n",
    "# last_case = None\n",
    "# def incrementalElapsed(log_row):\n",
    "#     global last_timestamp, last_case\n",
    "#     if last_case == None or log_row[\"case:concept:name\"] != last_case:\n",
    "#         last_case = log_row[\"case:concept:name\"]\n",
    "#         last_timestamp = log_row[\"time:timestamp\"]\n",
    "#         return 0\n",
    "#     else:\n",
    "#         elapsed_seconds = log_row[\"time:timestamp\"] - last_timestamp\n",
    "#         last_timestamp = log_row[\"time:timestamp\"]\n",
    "#         return int(elapsed_seconds.total_seconds())\n",
    "\n",
    "# log_df[\"elapsed\"] = log_df.apply(incrementalElapsed, axis=\"columns\")\n",
    "\n",
    "# log_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add _status_ and _completed_ columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column _status_ with a more readable description of the _dismissal_ column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_df[\"dismissal\"].unique())\n",
    "\n",
    "def setStatus(log_row):\n",
    "    dismissal = log_row[\"dismissal\"]\n",
    "\n",
    "    if dismissal == \"#\":\n",
    "        return \"Prefecture\"\n",
    "    elif dismissal == \"G\":\n",
    "        return \"Judge\"\n",
    "    elif dismissal == \"NIL\":\n",
    "        return \"Not Payed\"\n",
    "    elif pd.isna(dismissal):\n",
    "        return \"Unknown\"\n",
    "    return dismissal\n",
    "\n",
    "log_df[\"status\"] = log_df.apply(setStatus, axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column _completed_, based on _status_ column, that shows if a process is completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setCompleted(log_row):\n",
    "    status = log_row[\"status\"]\n",
    "\n",
    "    if status in [\"Prefecture\", \"Judge\"]:\n",
    "        return \"Yes\"\n",
    "    elif status in [\"Not Payed\", \"Unknown\"]:\n",
    "        return \"No\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "log_df[\"completed\"] = log_df.apply(setCompleted, axis=\"columns\")\n",
    "\n",
    "log_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change column order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change order of columns to make the dataframe more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['case:concept:name', 'concept:name', 'org:resource', 'time:timestamp', # general attributes\n",
    "            'amount', 'expense', 'points', 'paymentAmount', # number attributes\n",
    "            'totalPaymentAmount', # current total amount paid by offender and total due (sum of fines, expenses and penalties)\n",
    "            'dismissal', 'status', \"completed\", # status code\n",
    "            'lastSent', 'vehicleClass', 'article', 'notificationType',\n",
    "            'lifecycle:transition', '@@index', '@@case_index']\n",
    "\n",
    "log_df = log_df[columns]\n",
    "\n",
    "log_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log = log_df.copy(deep=True)\n",
    "\n",
    "num_events = len(log_raw)\n",
    "num_cases = len(log_raw['case:concept:name'].unique())\n",
    "print(f\"Number of events: {num_events}\\nNumber of cases: {num_cases}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown-coded cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cases with \"unknown\" as _completed_ code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log = filtered_log[filtered_log['completed'] != \"Unknown\"]\n",
    "\n",
    "# unknown_cases = pm4py.filter_trace_attribute_values(filtered_log, 'completed', [\"Unknown\"], retain=True)\n",
    "# filtered_log = filtered_log[filtered_log[\"completed\"] != \"Unknown\"]\n",
    "# filtered_log = pd.concat([filtered_log, unknown_cases]).drop_duplicates(keep=False)\n",
    "\n",
    "legal_events = len(filtered_log)\n",
    "all_events = len(log_df)\n",
    "# print(f\"Filtered cases: {len(filtered_log['case:concept:name'].unique())}\")\n",
    "print(f\"Filtered events: {legal_events}/{all_events} ({round((legal_events/all_events) * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero duration cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate some statistics about raw logs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_durations = pm4py.get_all_case_durations(log_df)\n",
    "min_raw = min(case_durations)\n",
    "max_raw = max(case_durations)\n",
    "mean_raw = np.mean(case_durations)\n",
    "\n",
    "print(f\"Min Case Duration: {min_raw}\\nMax Case Duration: {max_raw}\\nMean Case Duration: {mean_raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter cases with duration 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_not_zero = min([x for x in case_durations if x>0])\n",
    "print(min_not_zero)\n",
    "print(max_raw)\n",
    "filtered_log = pm4py.filter_case_performance(filtered_log, min_not_zero, max_raw)\n",
    "\n",
    "legal_cases = len(filtered_log['case:concept:name'].unique())\n",
    "all_cases = len(log_df['case:concept:name'].unique())\n",
    "print(f\"Filtered cases: {legal_cases}/{all_cases} ({round((legal_cases/all_cases) * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start/End activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cases with illegal start activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pm4py.get_start_activities(filtered_log))\n",
    "\n",
    "# filtered_log = pm4py.filter_start_activities(filtered_log, ['Create Fine'])\n",
    "\n",
    "# legal_start_cases = len(filtered_log['case:concept:name'].unique())\n",
    "# all_cases = len(log_df['case:concept:name'].unique())\n",
    "# print(f\"Filtered events: {len(filtered_log)}\")\n",
    "# print(f\"Filtered cases: {legal_start_cases}/{all_cases} ({round((legal_start_cases/all_cases) * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove cases with illegal end activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm4py.get_end_activities(filtered_log))\n",
    "\n",
    "filtered_log = pm4py.filter_end_activities(filtered_log, ['Payment', 'Send for Credit Collection', 'Send Appeal to Prefecture', 'Appeal to Judge'])\n",
    "\n",
    "legal_cases = len(filtered_log['case:concept:name'].unique())\n",
    "all_cases = len(log_df['case:concept:name'].unique())\n",
    "print(f\"Filtered events: {len(filtered_log)}\")\n",
    "print(f\"Filtered cases: {legal_cases}/{all_cases} ({round((legal_cases/all_cases) * 100, 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Uplift Trail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starting point of the project is the log, provided as an ```.xes``` file. The log is processed in two phases: cleaning and filtering. In the cleaning process, the log is converted to a DataFrame, compatible with the libraries used, some parts of the log are removed (_matricola_), changed (_amount_) or added (_status_, _completed_, etc.). In the filtering process, data not useful for analysis are removed through a series of filters (time, values and activies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these two preliminary phases, statistical methods are used to do a general analysis of the data contained in the log."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General case durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_durations = pm4py.get_all_case_durations(filtered_log)\n",
    "min_duration = min(case_durations)\n",
    "min_time = datetime.timedelta(seconds=min_duration)\n",
    "max_duration = max(case_durations)\n",
    "max_time = datetime.timedelta(seconds=max_duration)\n",
    "mean_duration = np.mean(case_durations)\n",
    "mean_time = datetime.timedelta(seconds=mean_duration)\n",
    "\n",
    "print(f\"Min Case Duration: {min_duration} -> {min_time}\")\n",
    "print(f\"Max Case Duration: {max_duration} -> {max_time}\")\n",
    "print(f\"Mean Case Duration: {mean_duration} -> {mean_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_durations_df = filtered_log.groupby('case:concept:name', as_index=False).agg(\\\n",
    "    StartTime = ('time:timestamp', lambda x: x.min()),\n",
    "    Duration = ('time:timestamp', lambda x: x.max() - x.min())\n",
    ")\n",
    "\n",
    "def format_duration(row):\n",
    "    total_seconds = int(row.total_seconds())\n",
    "    # hours, remainder = divmod(total_seconds, 3600)\n",
    "    # minutes, seconds = divmod(remainder, 60)\n",
    "    # return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "    return total_seconds\n",
    "\n",
    "case_durations_df['Duration'] = case_durations_df['Duration'].apply(format_duration)\n",
    "\n",
    "def att(row):\n",
    "    return \"att\"\n",
    "\n",
    "case_durations_df[\"concept:name\"] = case_durations_df.apply(att, axis=\"columns\")\n",
    "\n",
    "def pick_year(row):\n",
    "    return datetime.datetime.strptime(str(row[\"StartTime\"]), \"%Y-%m-%d %H:%M:%S%z\").year\n",
    "\n",
    "def pick_month(row):\n",
    "    return datetime.datetime.strptime(str(row[\"StartTime\"]), \"%Y-%m-%d %H:%M:%S%z\").month\n",
    "\n",
    "def pick_day(row):\n",
    "    return datetime.datetime.strptime(str(row[\"StartTime\"]), \"%Y-%m-%d %H:%M:%S%z\").day\n",
    "\n",
    "case_durations_df[\"StartYear\"] = case_durations_df.apply(pick_year, axis=\"columns\")\n",
    "case_durations_df[\"StartMonth\"] = case_durations_df.apply(pick_month, axis=\"columns\")\n",
    "case_durations_df[\"StartDay\"] = case_durations_df.apply(pick_day, axis=\"columns\")\n",
    "\n",
    "case_durations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case frequency by duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = [\"Less than 1 day\",\n",
    "            \"Less than 1 week\",\n",
    "            \"Less than 1 month\",\n",
    "            \"Less than 6 months\",\n",
    "            \"Less than 1 year\",\n",
    "            \"Less than 2 years\",\n",
    "            \"Less than 5 years\",\n",
    "            \"Others\"]\n",
    "freqs = [len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24]), # 1 day\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24 * 7]), # 1 week\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24*7 * 4]), # 1 month\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24*7*4 * 6]), # 6 months\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24 * 365]), # 1 year\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24*365 * 2]), # 2 years\n",
    "            len(case_durations_df[case_durations_df[\"Duration\"] <= 60*60*24*365 * 5]), # 5 years\n",
    "            len(case_durations_df)]\n",
    "\n",
    "for x in range(len(freqs)-1, 0, -1):\n",
    "    freqs[x] -= freqs[x-1]\n",
    "\n",
    "for x in range(len(freqs)):\n",
    "    print(f\"{xlabels[x].ljust(20, ' ')}: {str(freqs[x]).ljust(5, ' ')} ({round(freqs[x]/len(case_durations_df) * 100, 2)}%)\")\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(xlabels, freqs)\n",
    "plt.xlabel(\"Duration\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Case frequency by duration\")\n",
    "\n",
    "y_custom_ticks = [x*5000 for x in range(10)]\n",
    "y_custom_ticks.remove(5000)\n",
    "y_custom_ticks.append(min(freqs[:len(freqs)-1]))\n",
    "y_custom_ticks.append(max(freqs))\n",
    "y_custom_ticks.sort()\n",
    "\n",
    "plt.yticks(y_custom_ticks)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm4py.get_end_activities(filtered_log))\n",
    "\n",
    "end_acts = pm4py.get_end_activities(filtered_log)\n",
    "x_axis = []\n",
    "y_axis = []\n",
    "\n",
    "for i in end_acts.keys():\n",
    "    x_axis.append(i)\n",
    "    y_axis.append(end_acts[i])\n",
    "\n",
    "others_amount = end_acts[\"Appeal to Judge\"]+end_acts[\"Send for Credit Collection\"]+end_acts[\"Send Appeal to Prefecture\"]\n",
    "print(f\"Payments: {end_acts['Payment']}\")\n",
    "print(f\"Others: {others_amount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paid_cases = pm4py.filter_end_activities(filtered_log, ['Payment'])\n",
    "unpaid_cases = pm4py.filter_end_activities(filtered_log, ['Payment'], retain=False)\n",
    "\n",
    "# print(f\"Paid fine min: {paid_cases[paid_cases['concept:name'] == 'Create Fine']['amount'].min()}\")\n",
    "# print(f\"Paid fine max: {paid_cases[paid_cases['concept:name'] == 'Create Fine']['amount'].max()}\")\n",
    "# print(f\"Paid fine mean: {paid_cases[paid_cases['concept:name'] == 'Create Fine']['amount'].mean()}\")\n",
    "\n",
    "# print(f\"Unpaid fine min: {unpaid_cases[unpaid_cases['concept:name'] == 'Create Fine']['amount'].min()}\")\n",
    "# print(f\"Unpaid fine max: {unpaid_cases[unpaid_cases['concept:name'] == 'Create Fine']['amount'].max()}\")\n",
    "# print(f\"Unpaid fine mean: {unpaid_cases[unpaid_cases['concept:name'] == 'Create Fine']['amount'].mean()}\")\n",
    "\n",
    "# paid_cases.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paid_ids = paid_cases[\"case:concept:name\"].unique().tolist()\n",
    "unpaid_ids = unpaid_cases[\"case:concept:name\"].unique().tolist()\n",
    "\n",
    "paid_durations = pm4py.filter_event_attribute_values(case_durations_df, \"case:concept:name\", paid_ids) #case_durations_df[case_durations_df[\"case:concept:name\"] in paid_ids]\n",
    "unpaid_durations = pm4py.filter_event_attribute_values(case_durations_df, \"case:concept:name\", unpaid_ids) #case_durations_df[case_durations_df[\"case:concept:name\"] in unpaid_ids]\n",
    "\n",
    "# for c in paid_ids:\n",
    "#     # print(c)\n",
    "#     a = case_durations_df[case_durations_df[\"case:concept:name\"] == c]\n",
    "#     print(a.iloc[0][\"Duration\"])\n",
    "\n",
    "print(f\"Paid min duration: {paid_durations['Duration'].min()}\")\n",
    "print(f\"Paid max duration: {paid_durations['Duration'].max()}\")\n",
    "print(f\"Paid mean duration: {paid_durations['Duration'].mean()}\")\n",
    "\n",
    "print(f\"Paid min duration: {unpaid_durations['Duration'].min()}\")\n",
    "print(f\"Paid max duration: {unpaid_durations['Duration'].max()}\")\n",
    "print(f\"Paid mean duration: {unpaid_durations['Duration'].mean()}\")\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar([\"Paid\", \"Others\"], [paid_durations['Duration'].mean()/(60*60*24), unpaid_durations['Duration'].mean()/(60*60*24)], width=0.4)\n",
    "# plt.xlabel(\"Duration\")\n",
    "plt.ylabel(\"Duration (days)\")\n",
    "# plt.title(\"Case frequency by duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tolgo le varianti senza invio della multa perché non fanno parte della correlazione che cerco\n",
    "log_new_paid = pm4py.filter_variants(paid_cases, [('Create Fine', 'Payment')], retain=False)\n",
    "\n",
    "# Filter rows for 'Create Fine' and 'Send Fine'\n",
    "create_fine_df = log_new_paid[log_new_paid['concept:name'] == 'Create Fine']\n",
    "send_fine_df = log_new_paid[log_new_paid['concept:name'] == 'Send Fine']\n",
    "\n",
    "# Merge the two DataFrames on 'case:concept:name'\n",
    "merged_df = pd.merge(create_fine_df, send_fine_df, on='case:concept:name', suffixes=('_create', '_send'))\n",
    "\n",
    "time_differences_paid = (merged_df['time:timestamp_send'] - merged_df['time:timestamp_create']).tolist()\n",
    "\n",
    "print(f\"Paid timeliness min: {min(time_differences_paid)}\")\n",
    "print(f\"Paid timeliness max: {max(time_differences_paid)}\")\n",
    "paid_mean = sum([int(x.total_seconds()) for x in time_differences_paid])/len(time_differences_paid)\n",
    "print(f\"Paid timeliness mean: {paid_mean}\")\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(range(len(time_differences_paid)), [int(x.total_seconds()) for x in time_differences_paid])\n",
    "plt.xlabel('Case')\n",
    "plt.ylabel('Notification timeliness')\n",
    "plt.title('Scatter Plot of Notification timeliness (paid)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows for 'Create Fine' and 'Send Fine'\n",
    "create_fine_df = unpaid_cases[unpaid_cases['concept:name'] == 'Create Fine']\n",
    "send_fine_df = unpaid_cases[unpaid_cases['concept:name'] == 'Send Fine']\n",
    "\n",
    "# Merge the two DataFrames on 'case:concept:name'\n",
    "merged_df = pd.merge(create_fine_df, send_fine_df, on='case:concept:name', suffixes=('_create', '_send'))\n",
    "\n",
    "time_differences_unpaid = (merged_df['time:timestamp_send'] - merged_df['time:timestamp_create']).tolist()\n",
    "\n",
    "print(f\"Unpaid timeliness min: {min(time_differences_unpaid)}\")\n",
    "print(f\"Unpaid timeliness max: {max(time_differences_unpaid)}\")\n",
    "unpaid_mean = sum([int(x.total_seconds()) for x in time_differences_unpaid])/len(time_differences_unpaid)\n",
    "print(f\"Unpaid timeliness mean: {unpaid_mean}\")\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(range(len(time_differences_unpaid)), [int(x.total_seconds()) for x in time_differences_unpaid])\n",
    "plt.xlabel('Case')\n",
    "plt.ylabel('Notification timeliness')\n",
    "plt.title('Scatter Plot of Notification timeliness (unpaid)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "t_stat, p_val = ttest_ind([int(x.total_seconds()) for x in time_differences_paid], [int(x.total_seconds()) for x in time_differences_unpaid], equal_var=False)\n",
    "\n",
    "print(f\"T-stat: {t_stat}\\nP-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [int(x) for x in case_durations_df[\"StartMonth\"].unique().tolist()]\n",
    "months.sort()\n",
    "\n",
    "paid_case_durations = pm4py.filter_event_attribute_values(case_durations_df, \"case:concept:name\", paid_cases[\"case:concept:name\"].unique().tolist())\n",
    "\n",
    "means = []\n",
    "amounts = []\n",
    "for x in months:\n",
    "    filtered_durations = paid_case_durations[paid_case_durations[\"StartMonth\"] == x]\n",
    "    means.append(filtered_durations[\"Duration\"].mean())\n",
    "    amounts.append(len(filtered_durations))\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(months, amounts)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.title(\"Paid cases by month\")\n",
    "plt.xticks(months, [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [int(x) for x in case_durations_df[\"StartMonth\"].unique().tolist()]\n",
    "months.sort()\n",
    "\n",
    "unpaid_case_durations = pm4py.filter_event_attribute_values(case_durations_df, \"case:concept:name\", unpaid_cases[\"case:concept:name\"].unique().tolist())\n",
    "\n",
    "means = []\n",
    "amounts = []\n",
    "for x in months:\n",
    "    filtered_durations = unpaid_case_durations[unpaid_case_durations[\"StartMonth\"] == x]\n",
    "    means.append(filtered_durations[\"Duration\"].mean())\n",
    "    amounts.append(len(filtered_durations))\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.bar(months, amounts)\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.title(\"Unpaid cases by month\")\n",
    "plt.xticks(months, [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"], rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process discover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_top_variants_info(input_log, k=5):\n",
    "#     filtered_log_top = pm4py.filter_variants_top_k(input_log, k)\n",
    "\n",
    "#     num_events = len(filtered_log)\n",
    "#     num_events_top = len(filtered_log_top)\n",
    "#     num_cases = len(filtered_log['case:concept:name'].unique())\n",
    "#     num_cases_top = len(filtered_log_top['case:concept:name'].unique())\n",
    "#     print(f\"Number of events: {num_events_top}/{num_events} ({round(num_events_top/num_events * 100, 2)}%)\")\n",
    "#     print(f\"Number of cases: {num_cases_top}/{num_cases} ({round(num_cases_top/num_cases * 100, 2)}%)\")\n",
    "\n",
    "#     net, im, fm = pm4py.discover_petri_net_inductive(filtered_log_top)\n",
    "#     pm4py.view_petri_net(net, im, fm, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_top_variants_info(filtered_log, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_top_variants_info(filtered_log, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_top_variants_info(filtered_log, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_top_variants_info(filtered_log, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
